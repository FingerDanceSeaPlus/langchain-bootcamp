{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e10b374",
   "metadata": {},
   "source": [
    "# çŸ­æœŸè®°å¿†\n",
    "## åŸºç¡€æ¦‚å¿µ\n",
    "çŸ­æœŸè®°å¿†å…è®¸åº”ç”¨ç¨‹åºè®°ä½å•ä¸ªçº¿ç¨‹æˆ–ä¼šè¯ä¸­çš„å…ˆå‰äº¤äº’ã€‚\n",
    "\n",
    "å¯¹è¯å†å²æ˜¯æœ€å¸¸è§çš„çŸ­æœŸè®°å¿†å½¢å¼ï¼Œå¯¹ä»Šå¤©çš„llmæ¥è¯´ï¼Œé•¿æ—¶é—´çš„å¯¹è¯æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼›å®Œæ•´çš„å†å²è®°å½•å¯èƒ½ä¸é€‚åˆLLMçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œä»è€Œå¯¼è‡´ä¸Šä¸‹æ–‡ä¸¢å¤±æˆ–é”™è¯¯ã€‚\n",
    "\n",
    "å³ä½¿æ‚¨çš„æ¨¡å‹æ”¯æŒå®Œæ•´çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¤§å¤šæ•°llmåœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶ä»ç„¶è¡¨ç°ä¸ä½³ã€‚ä»–ä»¬ä¼šè¢«é™ˆè…æˆ–ç¦»é¢˜çš„å†…å®¹â€œåˆ†æ•£æ³¨æ„åŠ›â€ï¼ŒåŒæ—¶è¿˜è¦æ‰¿å—è¾ƒæ…¢çš„å“åº”æ—¶é—´å’Œè¾ƒé«˜çš„æˆæœ¬ã€‚\n",
    "\n",
    "èŠå¤©æ¨¡å‹ä½¿ç”¨æ¶ˆæ¯æ¥å—ä¸Šä¸‹æ–‡ï¼Œæ¶ˆæ¯åŒ…æ‹¬æŒ‡ä»¤ï¼ˆç³»ç»Ÿæ¶ˆæ¯ï¼‰å’Œè¾“å…¥ï¼ˆäººå·¥æ¶ˆæ¯ï¼‰ã€‚åœ¨èŠå¤©åº”ç”¨ç¨‹åºä¸­ï¼Œæ¶ˆæ¯åœ¨äººå·¥è¾“å…¥å’Œæ¨¡å‹å“åº”ä¹‹é—´äº¤æ›¿ï¼Œå¯¼è‡´æ¶ˆæ¯åˆ—è¡¨éšç€æ—¶é—´çš„æ¨ç§»è€Œå˜é•¿ã€‚ç”±äºä¸Šä¸‹æ–‡çª—å£æ˜¯æœ‰é™çš„ï¼Œè®¸å¤šåº”ç”¨ç¨‹åºå¯ä»¥ä»ä½¿ç”¨æŠ€æœ¯åˆ é™¤æˆ–â€œå¿˜è®°â€è¿‡æ—¶çš„ä¿¡æ¯ä¸­è·ç›Šã€‚\n",
    "\n",
    "## ä½¿ç”¨\n",
    "LangChainçš„ä»£ç†å°†çŸ­æœŸè®°å¿†ä½œä¸ºagentçŠ¶æ€çš„ä¸€éƒ¨åˆ†è¿›è¡Œç®¡ç†ã€‚\n",
    "é€šè¿‡å°†è¿™äº›å­˜å‚¨åœ¨å›¾çš„çŠ¶æ€ä¸­ï¼Œä»£ç†å¯ä»¥è®¿é—®ç»™å®šä¼šè¯çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶ä¿æŒä¸åŒçº¿ç¨‹ä¹‹é—´çš„åˆ†ç¦»ã€‚\n",
    "ä½¿ç”¨checkpointå°†çŠ¶æ€æŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼ˆæˆ–å†…å­˜ï¼‰ä¸­ï¼Œå› æ­¤å¯ä»¥éšæ—¶æ¢å¤çº¿ç¨‹ã€‚\n",
    "å½“è°ƒç”¨ä»£ç†æˆ–å®Œæˆä¸€ä¸ªæ­¥éª¤ï¼ˆå¦‚å·¥å…·è°ƒç”¨ï¼‰æ—¶ï¼Œä¼šæ›´æ–°çŸ­æœŸå†…å­˜ï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªæ­¥éª¤å¼€å§‹æ—¶è¯»å–çŠ¶æ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d748e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5\",\n",
    "    [get_user_info],\n",
    "    checkpointer=InMemorySaver(),  #ç®€å•ä¿å­˜åœ¨å†…å­˜ä¸­\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42047975",
   "metadata": {},
   "source": [
    "åœ¨ç”Ÿäº§åœºæ™¯ä¸­ï¼Œä½¿ç”¨æ•°æ®åº“å¤‡ä»½çš„checkpointæ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langgraph-checkpoint-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94def341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver  \n",
    "\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup() # auto create tables in PostgresSql\n",
    "    agent = create_agent(\n",
    "        \"gpt-5\",\n",
    "        [get_user_info],\n",
    "        checkpointer=checkpointer,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680d96a",
   "metadata": {},
   "source": [
    "## è‡ªå®šä¹‰agentè®°å¿†\n",
    "é»˜è®¤æƒ…å†µä¸‹ï¼Œagentä½¿ç”¨AgentStateç®¡ç†çŸ­æœŸè®°å¿†ï¼Œç‰¹åˆ«æ˜¯messageé”®ç®¡ç†å¯¹è¯å†å²ã€‚\n",
    "\n",
    "å¯ä»¥é€šè¿‡ç»§æ‰¿AgentStateç±»æ¥æ·»åŠ é¢å¤–çš„å­—æ®µï¼ŒCustom state schemas are passed to create_agent using the state_schema parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "class CustomAgentState(AgentState):  \n",
    "    user_id: str\n",
    "    preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5\",\n",
    "    [get_user_info],\n",
    "    state_schema=CustomAgentState,  \n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",  \n",
    "        \"preferences\": {\"theme\": \"dark\"}  \n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32000a",
   "metadata": {},
   "source": [
    "## å¸¸è§æ¨¡å¼\n",
    "é•¿å¯¹è¯å¯èƒ½è¶…è¿‡LLMçš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼Œæœ‰å››ç§è§£å†³æ–¹å¼ï¼š\n",
    "### 1. è£åˆ‡å¯¹è¯\n",
    "å¤§å¤šæ•°llméƒ½æœ‰ä¸€ä¸ªæœ€å¤§æ”¯æŒçš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»¥ä»¤ç‰Œè¡¨ç¤ºï¼‰ã€‚\n",
    "\n",
    "ä¸€ç§å†³å®šé˜¶æ®µæ—¶æœºçš„æ–¹æ³•æ˜¯ç»Ÿè®¡æ¶ˆæ¯å†å²çš„tokenæ•°ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ”¯æŒçš„çª—å£ã€‚\n",
    "\n",
    "è¦åœ¨ä»£ç†ä¸­ä¿®æ”¹æ¶ˆæ¯å†å²è®°å½•ï¼Œå¯ä»¥ä½¿ç”¨@before_modelä¸­é—´ä»¶è£…é¥°å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82caea0",
   "metadata": {},
   "source": [
    "### 2.åˆ é™¤ä¿¡æ¯\n",
    "æ‚¨å¯ä»¥ä»å›¾çŠ¶æ€ä¸­åˆ é™¤æ¶ˆæ¯ä»¥ç®¡ç†æ¶ˆæ¯å†å²è®°å½•ã€‚\n",
    "å½“æ‚¨æƒ³è¦åˆ é™¤ç‰¹å®šæ¶ˆæ¯æˆ–æ¸…é™¤æ•´ä¸ªæ¶ˆæ¯å†å²è®°å½•æ—¶ï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚\n",
    "è¦ä»å›¾çŠ¶æ€ä¸­åˆ é™¤æ¶ˆæ¯ï¼Œå¯ä»¥ä½¿ç”¨RemoveMessageæ–¹æ³•ã€‚\n",
    "\n",
    "ä¸ºäº†ä½¿è¯¥æ–¹æ³•å·¥ä½œï¼Œè¦ä½¿ç”¨å¸¦æœ‰add_messages reducerçš„çŠ¶æ€é”®ã€‚ï¼ˆreduceræ˜¯ç†è§£æ¥è‡ªèŠ‚ç‚¹çš„æ›´æ–°å¦‚ä½•åº”ç”¨äºçŠ¶æ€çš„å…³é”®ã€‚Stateä¸­çš„æ¯ä¸ªé”®éƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„reducerå‡½æ•°ã€‚å¦‚æœæ²¡æœ‰æ˜¾å¼æŒ‡å®šreducerå‡½æ•°ï¼Œåˆ™å‡å®šå¯¹è¯¥é”®çš„æ‰€æœ‰æ›´æ–°éƒ½åº”è¯¥è¦†ç›–å®ƒã€‚ï¼‰\n",
    "\n",
    "é»˜è®¤çš„AgentStateç±»åŒ…å«ä¸€ä¸ªåä¸ºadd_messagesçš„reducerã€‚\n",
    "\n",
    "è¦åˆ é™¤ç‰¹å®šæ¶ˆæ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baabfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage  \n",
    "\n",
    "def delete_messages(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45497531",
   "metadata": {},
   "source": [
    "åˆ é™¤å…¨éƒ¨æ¶ˆæ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "def delete_messages(state):\n",
    "    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f442814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 1.0.3\n",
      "langchain-core: 1.0.2\n",
      "[('human', \"hi! I'm bob\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?')]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?'), ('human', \"what's my name?\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob! ğŸ˜Š')]\n",
      "[('human', \"what's my name?\"), ('ai', 'Your name is Bob! ğŸ˜Š')]\n"
     ]
    }
   ],
   "source": [
    "# python\n",
    "import pkg_resources\n",
    "print(\"langchain:\", pkg_resources.get_distribution(\"langchain\").version)\n",
    "print(\"langchain-core:\", pkg_resources.get_distribution(\"langchain-core\").version)\n",
    "from langchain.messages import RemoveMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "# é…ç½®èŠå¤©æ¨¡å‹\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # æ­¤å¤„ä»¥qwen-plusä¸ºä¾‹ï¼Œæ‚¨å¯æŒ‰éœ€æ›´æ¢æ¨¡å‹åç§°ã€‚æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff889d9",
   "metadata": {},
   "source": [
    "### æ€»ç»“ä¿¡æ¯\n",
    "å¦‚ä¸Šæ‰€ç¤ºï¼Œä¿®å‰ªæˆ–åˆ é™¤æ¶ˆæ¯çš„é—®é¢˜æ˜¯ï¼Œå¯èƒ½ä¼šåœ¨ç­›é€‰æ¶ˆæ¯é˜Ÿåˆ—æ—¶ä¸¢å¤±ä¿¡æ¯ã€‚å› æ­¤ï¼Œä¸€äº›åº”ç”¨ç¨‹åºå—ç›Šäºä½¿ç”¨èŠå¤©æ¨¡å‹æ€»ç»“æ¶ˆæ¯å†å²çš„æ›´å¤æ‚çš„æ–¹æ³•ã€‚\n",
    "![](./Imaegs/summary.avif)\n",
    "\n",
    "ä½¿ç”¨å†…å»ºçš„SummarizationMiddlewareæ¥æ€»ç»“ä¿¡æ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dd4291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! ğŸ˜Š  \n",
      "And Iâ€™m glad to know you. Want me to call you something else? Just say the word!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n================================== Ai Message ==================================\\n\\nYour name is Bob!\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=model,\n",
    "            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b329e",
   "metadata": {},
   "source": [
    "##  è·å–è®°å¿†\n",
    "å¯ä»¥ä½¿ç”¨å¤šç§æ–¹æ³•è·å–å’Œä¿®æ”¹è®°å¿†ï¼š\n",
    "### å·¥å…·\n",
    "ä½¿ç”¨ToolRuntimeå‚æ•°è®¿é—®å·¥å…·ä¸­çš„çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ã€‚\n",
    "tool_runtimeå‚æ•°å¯¹å·¥å…·ç­¾åæ˜¯éšè—çš„ï¼ˆæ‰€ä»¥æ¨¡å‹çœ‹ä¸åˆ°å®ƒï¼‰ï¼Œä½†æ˜¯å·¥å…·å¯ä»¥é€šè¿‡å®ƒè®¿é—®çŠ¶æ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751e3457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's name is John Smith. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    user_id = runtime.state[\"user_id\"]\n",
    "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"look up user information\",\n",
    "    \"user_id\": \"user_123\"\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# > User is John Smith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd6732",
   "metadata": {},
   "source": [
    "è¦åœ¨æ‰§è¡ŒæœŸé—´ä¿®æ”¹ä»£ç†çš„çŸ­æœŸå†…å­˜ï¼ˆçŠ¶æ€ï¼‰ï¼Œå¯ä»¥ç›´æ¥ä»å·¥å…·è¿”å›çŠ¶æ€æ›´æ–°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11aa8b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='greet the user', additional_kwargs={}, response_metadata={}, id='d7fa67d0-6d74-44fc-a11c-34dc2561d064'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 182, 'total_tokens': 198, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-1aebbd39-7a47-4efe-8b88-72ca347706e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--e048ca61-f4b3-4dbd-814f-6cec11a91543-0', tool_calls=[{'name': 'update_user_info', 'args': {}, 'id': 'call_a6dbfe00dcf445cab08a4d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 16, 'total_tokens': 198, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='Successfully looked up user information', name='update_user_info', id='208179b8-17b1-47e7-b310-669e2eefbaca', tool_call_id='call_a6dbfe00dcf445cab08a4d'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 217, 'total_tokens': 232, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-45dd93e0-233a-4a14-b981-275dc5300295', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--5b263911-6da0-4876-ba8a-dc8c2d985e73-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_ffeab86a055040ea9beebe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 15, 'total_tokens': 232, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='Hello John Smith!', name='greet', id='95e6bc4c-78e9-42a1-957a-bf6e1489b7ca', tool_call_id='call_ffeab86a055040ea9beebe'),\n",
       "  AIMessage(content='Hello John Smith! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 249, 'total_tokens': 260, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-71894904-4b7c-4c3b-97cf-de98d2bab3e2', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--15064141-f2d0-41fc-a537-b875aede720f-0', usage_metadata={'input_tokens': 249, 'output_tokens': 11, 'total_tokens': 260, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})],\n",
       " 'user_name': 'John Smith'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.types import Command\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CustomState(AgentState):  \n",
    "    user_name: str\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def update_user_info(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState],\n",
    ") -> Command:\n",
    "    \"\"\"Look up and update user info.\"\"\"\n",
    "    user_id = runtime.context.user_id  \n",
    "    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={\n",
    "        \"user_name\": name,\n",
    "        # update the message history\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                \"Successfully looked up user information\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def greet(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState]\n",
    ") -> str:\n",
    "    \"\"\"Use this to greet the user once you found their info.\"\"\"\n",
    "    user_name = runtime.state[\"user_name\"]\n",
    "    return f\"Hello {user_name}!\"\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState,\n",
    "    context_schema=CustomContext,  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n",
    "    context=CustomContext(user_id=\"user_123\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310b776",
   "metadata": {},
   "source": [
    "### æç¤ºè¯\n",
    "å¯ä»¥è®¿é—®ä¸­é—´ä»¶ä¸­çš„çŸ­æœŸå†…å­˜ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥åŸºäºä¼šè¯å†å²æˆ–è‡ªå®šä¹‰çŠ¶æ€å­—æ®µåˆ›å»ºåŠ¨æ€æç¤ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f6948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in SF?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_cd0680092daa4118b53405)\n",
      " Call ID: call_cd0680092daa4118b53405\n",
      "  Args:\n",
      "    city: San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in San Francisco is always sunny!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in San Francisco is always sunny, John Smith!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31måœ¨å½“å‰å•å…ƒæ ¼æˆ–ä¸Šä¸€ä¸ªå•å…ƒæ ¼ä¸­æ‰§è¡Œä»£ç æ—¶ Kernel å´©æºƒã€‚\n",
      "\u001b[1;31mè¯·æŸ¥çœ‹å•å…ƒæ ¼ä¸­çš„ä»£ç ï¼Œä»¥ç¡®å®šæ•…éšœçš„å¯èƒ½åŸå› ã€‚\n",
      "\u001b[1;31må•å‡»<a href='https://aka.ms/vscodeJupyterKernelCrash'>æ­¤å¤„</a>äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚\n",
      "\u001b[1;31mæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Jupyter <a href='command:jupyter.viewOutput'>log</a>ã€‚"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from typing import TypedDict\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "class CustomContext(TypedDict):\n",
    "    user_name: str\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is always sunny!\"\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context[\"user_name\"]\n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=CustomContext,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=CustomContext(user_name=\"John Smith\"),\n",
    ")\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2708f640",
   "metadata": {},
   "source": [
    "### before model\n",
    "è®¿é—®@before_modelä¸­é—´ä»¶ä¸­çš„çŸ­æœŸå†…å­˜ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥ä¾¿åœ¨æ¨¡å‹è°ƒç”¨ä¹‹å‰å¤„ç†æ¶ˆæ¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb257cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c7c90",
   "metadata": {},
   "source": [
    "### after model\n",
    "è®¿é—®@after_modelä¸­é—´ä»¶ä¸­çš„çŸ­æœŸå†…å­˜ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥ä¾¿åœ¨æ¨¡å‹è°ƒç”¨åå¤„ç†æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81388263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "\n",
    "@after_model\n",
    "def validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove messages containing sensitive words.\"\"\"\n",
    "    STOP_WORDS = [\"password\", \"secret\"]\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if any(word in last_message.content for word in STOP_WORDS):\n",
    "        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[],\n",
    "    middleware=[validate_response],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a3ce3",
   "metadata": {},
   "source": [
    "# é•¿æœŸè®°å¿†\n",
    "## è®°å¿†å­˜å‚¨\n",
    "LangGraphå°†é•¿æœŸè®°å¿†å­˜å‚¨ä¸ºå­˜å‚¨åº“ä¸­çš„JSONæ–‡æ¡£ã€‚\n",
    "æ¯ä¸ªå†…å­˜éƒ½ç»„ç»‡åœ¨ä¸€ä¸ªè‡ªå®šä¹‰åç§°ç©ºé—´ï¼ˆç±»ä¼¼äºæ–‡ä»¶å¤¹ï¼‰å’Œä¸€ä¸ªä¸åŒçš„é”®ï¼ˆç±»ä¼¼äºæ–‡ä»¶åï¼‰ä¸‹ã€‚åç§°ç©ºé—´é€šå¸¸åŒ…æ‹¬ç”¨æˆ·æˆ–ç»„ç»‡idæˆ–å…¶ä»–ä½¿ç»„ç»‡ä¿¡æ¯æ›´å®¹æ˜“çš„æ ‡ç­¾ã€‚\n",
    "è¿™ç§ç»“æ„ä½¿è®°å¿†çš„å±‚æ¬¡ç»„ç»‡æˆä¸ºå¯èƒ½ã€‚ç„¶åé€šè¿‡å†…å®¹è¿‡æ»¤å™¨æ”¯æŒè·¨åç§°ç©ºé—´æœç´¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    # Replace with an actual embedding function or LangChain embeddings object\n",
    "    return [[1.0, 2.0] * len(texts)]\n",
    "\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": 2}) \n",
    "user_id = \"my-user\"\n",
    "application_context = \"chitchat\"\n",
    "namespace = (user_id, application_context) \n",
    "store.put( \n",
    "    namespace,\n",
    "    \"a-memory\",\n",
    "    {\n",
    "        \"rules\": [\n",
    "            \"User likes short, direct language\",\n",
    "            \"User only speaks English & python\",\n",
    "        ],\n",
    "        \"my-key\": \"my-value\",\n",
    "    },\n",
    ")\n",
    "# get the \"memory\" by ID\n",
    "item = store.get(namespace, \"a-memory\") \n",
    "# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\n",
    "items = store.search( \n",
    "    namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41313dbe",
   "metadata": {},
   "source": [
    "##  ä½¿ç”¨å·¥å…·è¯»å–é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\n",
    "store = InMemoryStore() \n",
    "\n",
    "# Write sample data to the store using the put method\n",
    "store.put( \n",
    "    (\"users\",),  # Namespace to group related data together (users namespace for user data)\n",
    "    \"user_123\",  # Key within the namespace (user ID as key)\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"language\": \"English\",\n",
    "    }  # Data to store for the given user\n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_user_info(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id\n",
    "    # Retrieve data from store - returns StoreValue object with value and metadata\n",
    "    user_info = store.get((\"users\",), user_id) \n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    tools=[get_user_info],\n",
    "    # Pass store to agent - enables agent to access store when running tools\n",
    "    store=store, \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n",
    "    context=Context(user_id=\"user_123\") \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f30274",
   "metadata": {},
   "source": [
    "## å†™å…¥æ¥è‡ªå·¥å…·çš„é•¿æœŸè®°å¿†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbe2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\n",
    "store = InMemoryStore() \n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# TypedDict defines the structure of user information for the LLM\n",
    "class UserInfo(TypedDict):\n",
    "    name: str\n",
    "\n",
    "# Tool that allows agent to update user information (useful for chat applications)\n",
    "@tool\n",
    "def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id \n",
    "    # Store data in the store (namespace, key, data)\n",
    "    store.put((\"users\",), user_id, user_info) \n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    tools=[save_user_info],\n",
    "    store=store, \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n",
    "    # user_id passed in context to identify whose information is being updated\n",
    "    context=Context(user_id=\"user_123\") \n",
    ")\n",
    "\n",
    "# You can access the store directly to get the value\n",
    "store.get((\"users\",), \"user_123\").value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
